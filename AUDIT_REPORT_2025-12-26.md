# Auditor√≠a de Seguridad y Hardening - Verity MVP

**Fecha**: 2025-12-26
**Auditor**: Sistema Automatizado
**Versi√≥n**: stable-tests-v1.1

---

## 1. FUENTES DE DATOS

### üî¥ RIESGO CR√çTICO: Fallback Silencioso a Supabase

**Ubicaci√≥n**: `src/verity/tools/run_table_query/__init__.py` l√≠neas 116-157

**Problema**:
```python
# Cargar tabla (buscar en uploads/canonical/ o fallback a Supabase)
canonical_path = Path("uploads/canonical")
for file in canonical_path.glob(f"*{table_name}*.csv"):
    ...
if table_file:
    df = pd.read_csv(table_file, encoding="utf-8")
else:
    # Fallback: cargar desde Supabase  <-- SILENCIOSO
```

**Riesgos**:
1. Si el archivo CSV no existe, el sistema cambia a Supabase SIN notificar al usuario
2. Los datos pueden ser diferentes entre CSV y Supabase
3. No hay logging de qu√© fuente se us√≥
4. El operador no sabe de d√≥nde vinieron los datos

**Recomendaci√≥n Inmediata**:
```python
# ANTES de elegir fallback, loguear expl√≠citamente
if table_file:
    logger.info(f"Loading table '{table_name}' from CSV: {table_file}")
    data_source = "csv"
else:
    logger.warning(f"CSV not found for '{table_name}', falling back to Supabase")
    data_source = "supabase"
```

### üü° RIESGO MEDIO: Glob Pattern Demasiado Permisivo

**Ubicaci√≥n**: l√≠nea 120

```python
for file in canonical_path.glob(f"*{table_name}*.csv"):
```

**Problema**: Si tengo `orders.csv` y `orders_backup.csv`, puede cargar cualquiera.

---

## 2. L√çMITES Y DEFAULTS PELIGROSOS

### üî¥ CR√çTICO: L√≠mite Default de 20,000 Filas

**Ubicaci√≥n**: `run_table_query/__init__.py` l√≠nea 81

```python
limit = input_data.get("limit", 20000)
```

**Problema**: 
- Schema dice `default: 1000` pero c√≥digo usa `20000`
- Discrepancia entre contrato y implementaci√≥n
- 20K filas pueden truncar resultados sin aviso

### üî¥ CR√çTICO: L√≠mite de 50 en Rankings

**Ubicaci√≥n**: `resolve_semantics/__init__.py` l√≠nea 332

```python
limit = min(int(match.group(1)), 50)  # max 50
```

**Problema**: Si el usuario pide "top 100", recibe 50 sin aviso.

### üü° MEDIO: L√≠mite Hardcodeado de 8 Candidatos

**Ubicaci√≥n**: `resolve_semantics/__init__.py` l√≠nea 140

```python
extracted = process.extract(
    phrase,
    aliases,
    scorer=fuzz.WRatio,
    limit=8,  # <-- Hardcodeado, no configurable
)
```

### üü° MEDIO: Cache TTL Hardcodeado

**Ubicaci√≥n**: `run_table_query/__init__.py` l√≠nea 31

```python
_CACHE_TTL_SECONDS = 120
```

No configurable via env/settings.

### üü° MEDIO: Batch Size de Supabase Hardcodeado

**Ubicaci√≥n**: l√≠nea 143

```python
batch_size = 1000
```

---

## 3. CACHE

### ‚úÖ Cache Key Completa

La cache key **S√ç incluye** todos los par√°metros relevantes:

```python
cache_key_content = json.dumps({
    "table": table_name,
    "metrics": metrics,
    "filters": filters_spec,
    "group_by": group_by,
    "limit": limit,
    "time_column": time_column,
    "time_grain": time_grain,
    "baseline_period": baseline_period,
    "compare_period": compare_period
}, sort_keys=True)
```

### üî¥ FALTA: `order_by` NO est√° en Cache Key

**Problema**: Dos queries con mismo contenido pero diferente `order_by` comparten cache.

```python
# FALTA:
"order_by": order_by,  # <-- NO EXISTE EN CACHE KEY
```

### üü° FALTA: Invalidaci√≥n en Cambio de Config

No hay mecanismo para invalidar cache cuando:
- Cambia el archivo CSV
- Cambia la configuraci√≥n
- Se reinicia la aplicaci√≥n (cache persiste en memoria)

### üü° FALTA: `columns` NO est√° en Cache Key

Si se pide la misma query con diferentes `columns`, retorna cache incorrecto.

---

## 4. PIPELINE CONTRACTS

### ‚úÖ Inputs/Outputs Expl√≠citos

Los schemas JSON definen contratos claros:
- `resolve_semantics/schema.json`
- `run_table_query/schema.json`

### üü° DEPENDENCIA IMPL√çCITA: Pipeline asume orden de etapas

**Ubicaci√≥n**: `pipeline.py` l√≠neas 248-310

```python
elif tool_name == "run_table_query@1.0":
    if not previous_output:
        raise ValueError("run_table_query requires previous resolve_semantics output")
```

No hay validaci√≥n de que `previous_output` tenga la estructura esperada.

### üü° DEPENDENCIA IMPL√çCITA: `result_metadata` opcional

El campo `result_metadata` se propaga pero es opcional. Si falta, el ResponseComposer asume comportamiento por defecto.

---

## 5. TESTS

### üî¥ Tests que Pasan por Accidente

**1. `test_compare_periods_v2`** - SKIP injustificado t√©cnicamente
- El test est√° bien dise√±ado
- El skip es por problema de arquitectura (app factory)
- Deber√≠a haber issue/ticket asociado

**2. Tests de Rate Limiting** - Estado inconsistente
- `test_rate_limit_auth_endpoint`: Puede pasar o fallar seg√∫n orden de ejecuci√≥n
- El rate limit store es global y no se limpia entre tests

### üü° Cobertura Faltante

**Rutas NO cubiertas**:
1. Fallback a Supabase (solo CSV en tests)
2. Cache hit (el fixture limpia cache)
3. Paginaci√≥n de Supabase (l√≠neas 141-152)
4. Validaci√≥n de NaN en columnas temporales
5. Operadores `LIKE` e `IN` en filtros complejos

### üü° Mocks Incompletos

**`test_auth_otp_jwt`**: Acepta 502 como √©xito
```python
assert authed.status_code in (200, 502), f"Auth should pass, got {authed.status_code}"
```
Esto enmascara errores reales del endpoint.

---

## 6. OBSERVABILIDAD

### üî¥ NO SE LOGUEA: Data Source Real Usado

El sistema no loguea si us√≥ CSV o Supabase.

### üî¥ NO SE LOGUEA: N√∫mero Real de Filas Cargadas

Antes del `limit`, no hay log de cu√°ntas filas hab√≠a originalmente.

### üî¥ NO SE LOGUEA: Operaci√≥n Ejecutada

No hay log de `operation=rank`, `operation=aggregate`, etc.

### ‚úÖ S√ç SE LOGUEA:
- Request/response con request_id
- Excepciones con c√≥digo y mensaje
- Latencia por tool (en m√©tricas)
- Errores de Gemini

---

## LISTA DE DEFAULTS PELIGROSOS

| Default | Ubicaci√≥n | Valor | Riesgo |
|---------|-----------|-------|--------|
| `limit` | run_table_query | 20000 | Truncaci√≥n silenciosa |
| `limit` (rankings) | resolve_semantics | 10 (max 50) | Truncaci√≥n silenciosa |
| `available_tables` | query_v2.py | `["orders"]` | Tabla incorrecta |
| `_CACHE_TTL_SECONDS` | run_table_query | 120 | No configurable |
| `batch_size` (Supabase) | run_table_query | 1000 | No configurable |
| `threshold` (fuzzy) | resolve_semantics | 85 | Hardcodeado |
| `ambiguity_margin` | resolve_semantics | 3 | Hardcodeado |

---

## CHECKLIST DE INVARIANTES DEL SISTEMA

### Invariantes que NUNCA Deben Romperse:

1. **[ ]** Cada query retornada debe incluir `data_source` en metadata
2. **[‚úÖ]** Nunca ejecutar query sin primero resolver sem√°ntica (validado en pipeline)
3. **[‚úÖ]** Nunca retornar datos sin `table_id` para trazabilidad
4. **[ ]** Nunca truncar resultados sin notificar `rows_truncated: true`
5. **[‚úÖ]** Nunca aceptar m√©trica con score < 85 (threshold)
6. **[‚úÖ]** Nunca aceptar operadores no soportados en filtros (whitelist expl√≠cita)
7. **[ ]** Nunca usar cache sin incluir TODOS los par√°metros en la key
8. **[‚úÖ]** Nunca ejecutar query si tabla no est√° en `available_tables`
9. **[‚úÖ]** Nunca retornar datos con NaN sin excepci√≥n tipada
10. **[ ]** Nunca cambiar de data source sin log expl√≠cito

---

## ACCIONES INMEDIATAS (HARDENING)

### Prioridad 1 (Cr√≠tica):
1. Agregar `order_by` y `columns` a cache key
2. Loguear data_source (CSV vs Supabase) en cada query
3. Alinear `limit` default entre schema (1000) y c√≥digo (20000)

### Prioridad 2 (Alta):
4. Agregar `rows_before_limit` al output para detectar truncaci√≥n
5. Loguear `original_row_count` antes de aplicar limit
6. Notificar al usuario cuando se aplica max 50 en rankings

### Prioridad 3 (Media):
7. Hacer configurable `_CACHE_TTL_SECONDS` via env
8. Agregar tests para fallback a Supabase
9. Agregar tests para cache hit scenarios
